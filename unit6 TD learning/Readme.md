

# TD LEARNING

It is a sample based algorithm which uses features of both Monte-Carlo and Dynamic Programming methods. Like Monte Carlo methods, TD methods can learn directly from raw experience without a model of the environmentâ€™s dynamics. Like DP, TD methods update estimates based in part on other learned estimates, without waiting for a final outcome (they bootstrap).

I have implemented the following algorithms

- [x] SARSA in CliffWorld
- [x] Qlearning in CliffWorld
- [x] Expected SARSA in CliffWorld



[Check out my notes on this unit](https://hackmd.io/CWNwEj-IR7eq5Nh6vUSefQ?both)

