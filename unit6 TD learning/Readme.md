

# TD LEARNING

It is a sample based algorithm which uses features of both Monte-Carlo and Dynamic Programming methods. Like Monte Carlo methods, TD methods can learn directly from raw experience without a model of the environmentâ€™s dynamics. Like DP, TD methods update estimates based in part on other learned estimates, without waiting for a final outcome (they bootstrap).

Sources of topics are:-

[Balaraman Ravindran's lectures](https://nptel.ac.in/courses/106106143/) 

[Sutton and Barto chapter 6](https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf)

[Google deepmind lectures by David Silver.](https://www.youtube.com/watch?v=0g4j2k_Ggc4&list=PLqYmG7hTraZBiG_XpjnPrSNw-1XQaM_gB&index=5)


I have implemented the following algorithms

- [x] SARSA in CliffWorld
- [x] Qlearning in CliffWorld
- [x] Expected SARSA in CliffWorld


### RESULTS:

![alt text](https://github.com/aadhithya14/RLResearch/blob/master/unit6%20TD%20learning/Results/cliffworld.png)

[Check out my notes on this unit](https://hackmd.io/CWNwEj-IR7eq5Nh6vUSefQ?both)

