# MULTI-ARMED BANDITS (IMMEDIATE REINFORCEMENT LEARNING)

Multi-armed Bandit problem is often considered as the Basement for all the Reinforcement learning problems. It is often ignored by researchers entering into the domain of Reinforcement learning. But Multi-Armed Bandits themselves constitute a separate literature in Reinforcement learning.

I would strongly advice everyone new in this field to go through the resources I  list down. These will be enough for theoretically studying  Multi-Armed Bandits ( atleast enough to get a basic understanding of immediate Reinforcement learning.).

1. [Just go through the introduction from wikipedia.](https://en.wikipedia.org/wiki/Multi-armed_bandit) 
2. [Professor Balaraman Ravindran's RL week 1 and week 2](https://nptel.ac.in/courses/106106143/)  
3. [Sutton and Barton chapter 2](https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf)
4. [Articles of Medium](https://towardsdatascience.com/multi-armed-bandits-and-reinforcement-learning-dc9001dcb8da) 

Code the algorithms as you go through the Algorithms.

I have implemented the following Algorithms

- [x]epsilon-greedy 

- [x]Softmax

- [x]UCB-(Upper Confidence Bound)

- [x]PAC-(Probably Approximately Correct)

- [x]Median Elimination

-[x]Thompson Sampling

-[ ]Other variants of UCB

-[ ]Policy Gradient Methods

After you are done with this I would recommend to go through the notes that I made in the following order. These notes summarize the topics in a brief manner.

[Upper Confidence Bounds](https://hackmd.io/Cwy1lsGdTziRDVx6Ig8csw?both)

[PAC Bandits](https://hackmd.io/nrU7NidVRi2MGdycizLWag)













